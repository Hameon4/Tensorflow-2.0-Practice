{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPn0IYCASyBPTTXEoETK4A5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hameon4/Tensorflow-2.0-Practice/blob/main/Linear_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DuqpwJ6Lr9UX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 - Load in the data\n",
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "j-A7qbnasSnD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 - Split the data into trainings and tests (X and Y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
        "N, D = X_train.shape\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(X_train)\n",
        "x_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "H9Pl79zYtHOE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model \n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(D,)),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EZU69WlcuD5H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdhBDE5IvJnB",
        "outputId": "7a8509f4-79b3-4b23-b1be-7b72330c3c64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 33ms/step - loss: 12.6199 - accuracy: 0.3202 - val_loss: 10.0432 - val_accuracy: 0.1862\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 9.7753 - accuracy: 0.0840 - val_loss: 9.7896 - val_accuracy: 0.1223\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.0439 - accuracy: 0.0682 - val_loss: 8.8700 - val_accuracy: 0.1170\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.2653 - accuracy: 0.1470 - val_loss: 8.2189 - val_accuracy: 0.1755\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.5607 - accuracy: 0.1339 - val_loss: 7.4679 - val_accuracy: 0.1330\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.8346 - accuracy: 0.1076 - val_loss: 6.8051 - val_accuracy: 0.1064\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.0835 - accuracy: 0.1365 - val_loss: 6.0536 - val_accuracy: 0.1649\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.3344 - accuracy: 0.1365 - val_loss: 5.3754 - val_accuracy: 0.1223\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.6969 - accuracy: 0.1444 - val_loss: 4.6396 - val_accuracy: 0.1277\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.9970 - accuracy: 0.1732 - val_loss: 4.0059 - val_accuracy: 0.1596\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3738 - accuracy: 0.2231 - val_loss: 3.4323 - val_accuracy: 0.1596\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.8986 - accuracy: 0.2415 - val_loss: 2.8869 - val_accuracy: 0.2287\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.3876 - accuracy: 0.2887 - val_loss: 2.4518 - val_accuracy: 0.2713\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.9822 - accuracy: 0.3596 - val_loss: 2.0970 - val_accuracy: 0.3298\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.6902 - accuracy: 0.4304 - val_loss: 1.8143 - val_accuracy: 0.3989\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4606 - accuracy: 0.4436 - val_loss: 1.5627 - val_accuracy: 0.4521\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2405 - accuracy: 0.5459 - val_loss: 1.3481 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0895 - accuracy: 0.5722 - val_loss: 1.2158 - val_accuracy: 0.5213\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9720 - accuracy: 0.6247 - val_loss: 1.0995 - val_accuracy: 0.5585\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8785 - accuracy: 0.6457 - val_loss: 1.0137 - val_accuracy: 0.5638\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8414 - accuracy: 0.6798 - val_loss: 0.9568 - val_accuracy: 0.6383\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7646 - accuracy: 0.7008 - val_loss: 0.8986 - val_accuracy: 0.6543\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7171 - accuracy: 0.7349 - val_loss: 0.8526 - val_accuracy: 0.6702\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6827 - accuracy: 0.7454 - val_loss: 0.8197 - val_accuracy: 0.6702\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.7664 - val_loss: 0.8235 - val_accuracy: 0.6543\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.7612 - val_loss: 0.7660 - val_accuracy: 0.7074\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6112 - accuracy: 0.7690 - val_loss: 0.7513 - val_accuracy: 0.6862\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5941 - accuracy: 0.7848 - val_loss: 0.7250 - val_accuracy: 0.7128\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.7848 - val_loss: 0.7104 - val_accuracy: 0.7128\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.7979 - val_loss: 0.6913 - val_accuracy: 0.7287\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5576 - accuracy: 0.7874 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5350 - accuracy: 0.8031 - val_loss: 0.6616 - val_accuracy: 0.7447\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.8031 - val_loss: 0.6625 - val_accuracy: 0.7766\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5066 - accuracy: 0.8320 - val_loss: 0.6532 - val_accuracy: 0.7340\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.8031 - val_loss: 0.6596 - val_accuracy: 0.7766\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.8241 - val_loss: 0.6273 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.8294 - val_loss: 0.6025 - val_accuracy: 0.7660\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4739 - accuracy: 0.8399 - val_loss: 0.5952 - val_accuracy: 0.7766\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.8241 - val_loss: 0.5811 - val_accuracy: 0.7766\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.8451 - val_loss: 0.5800 - val_accuracy: 0.7766\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.8268 - val_loss: 0.5903 - val_accuracy: 0.7979\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8478 - val_loss: 0.5714 - val_accuracy: 0.7713\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8530 - val_loss: 0.5521 - val_accuracy: 0.7979\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.8425 - val_loss: 0.5407 - val_accuracy: 0.7979\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.8635 - val_loss: 0.5577 - val_accuracy: 0.7819\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4212 - accuracy: 0.8609 - val_loss: 0.5317 - val_accuracy: 0.7979\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8556 - val_loss: 0.5147 - val_accuracy: 0.8032\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8635 - val_loss: 0.5089 - val_accuracy: 0.7872\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8661 - val_loss: 0.5013 - val_accuracy: 0.8032\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8688 - val_loss: 0.4955 - val_accuracy: 0.7979\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8688 - val_loss: 0.5080 - val_accuracy: 0.7979\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8504 - val_loss: 0.4880 - val_accuracy: 0.8298\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8635 - val_loss: 0.5027 - val_accuracy: 0.7872\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3789 - accuracy: 0.8504 - val_loss: 0.4788 - val_accuracy: 0.8404\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8740 - val_loss: 0.5008 - val_accuracy: 0.7872\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8635 - val_loss: 0.4677 - val_accuracy: 0.8457\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8819 - val_loss: 0.4547 - val_accuracy: 0.8032\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.8793 - val_loss: 0.4485 - val_accuracy: 0.8298\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.8766 - val_loss: 0.4460 - val_accuracy: 0.8457\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8793 - val_loss: 0.4422 - val_accuracy: 0.8032\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8793 - val_loss: 0.4363 - val_accuracy: 0.8457\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3358 - accuracy: 0.8871 - val_loss: 0.4286 - val_accuracy: 0.8404\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3296 - accuracy: 0.8976 - val_loss: 0.4304 - val_accuracy: 0.8032\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.8819 - val_loss: 0.4203 - val_accuracy: 0.8245\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8793 - val_loss: 0.4183 - val_accuracy: 0.8138\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.8898 - val_loss: 0.4169 - val_accuracy: 0.8564\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3135 - accuracy: 0.8950 - val_loss: 0.4071 - val_accuracy: 0.8245\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8819 - val_loss: 0.4132 - val_accuracy: 0.8617\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.8950 - val_loss: 0.4166 - val_accuracy: 0.7979\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8793 - val_loss: 0.3945 - val_accuracy: 0.8564\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8845 - val_loss: 0.3896 - val_accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3020 - accuracy: 0.8976 - val_loss: 0.3921 - val_accuracy: 0.8191\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8793 - val_loss: 0.3833 - val_accuracy: 0.8670\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2929 - accuracy: 0.8950 - val_loss: 0.3787 - val_accuracy: 0.8617\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.8845 - val_loss: 0.3756 - val_accuracy: 0.8457\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2894 - accuracy: 0.9029 - val_loss: 0.3730 - val_accuracy: 0.8457\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2883 - accuracy: 0.8845 - val_loss: 0.3762 - val_accuracy: 0.8191\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2805 - accuracy: 0.9003 - val_loss: 0.3646 - val_accuracy: 0.8617\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2801 - accuracy: 0.9003 - val_loss: 0.3641 - val_accuracy: 0.8511\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2810 - accuracy: 0.9029 - val_loss: 0.3590 - val_accuracy: 0.8564\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2779 - accuracy: 0.8871 - val_loss: 0.3561 - val_accuracy: 0.8670\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.8976 - val_loss: 0.3513 - val_accuracy: 0.8564\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2898 - accuracy: 0.9003 - val_loss: 0.3716 - val_accuracy: 0.8298\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2639 - accuracy: 0.9029 - val_loss: 0.3462 - val_accuracy: 0.8670\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2603 - accuracy: 0.9108 - val_loss: 0.3511 - val_accuracy: 0.8457\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2900 - accuracy: 0.8871 - val_loss: 0.3599 - val_accuracy: 0.8883\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2812 - accuracy: 0.8871 - val_loss: 0.3419 - val_accuracy: 0.8777\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2644 - accuracy: 0.9055 - val_loss: 0.3420 - val_accuracy: 0.8670\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2533 - accuracy: 0.8976 - val_loss: 0.3319 - val_accuracy: 0.8670\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.9055 - val_loss: 0.3290 - val_accuracy: 0.8670\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2475 - accuracy: 0.9108 - val_loss: 0.3311 - val_accuracy: 0.8723\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2446 - accuracy: 0.9055 - val_loss: 0.3307 - val_accuracy: 0.8883\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.9081 - val_loss: 0.3239 - val_accuracy: 0.8670\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2382 - accuracy: 0.9081 - val_loss: 0.3193 - val_accuracy: 0.8670\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2423 - accuracy: 0.9055 - val_loss: 0.3223 - val_accuracy: 0.8883\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2805 - accuracy: 0.8924 - val_loss: 0.3766 - val_accuracy: 0.8457\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2653 - accuracy: 0.8871 - val_loss: 0.3149 - val_accuracy: 0.8777\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2464 - accuracy: 0.9029 - val_loss: 0.3191 - val_accuracy: 0.8936\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2284 - accuracy: 0.9081 - val_loss: 0.3144 - val_accuracy: 0.8830\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.9081 - val_loss: 0.3092 - val_accuracy: 0.8723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(f'Train score: {model.evaluate(X_train, y_train)}')\n",
        "print(f'Test score: {model.evaluate(X_test, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geJb5ZK3vjVV",
        "outputId": "79de0ab5-4cb1-4dc3-fa1f-f4ae95f5b3dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9081\n",
            "Train score: [0.22488559782505035, 0.9081364870071411]\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8723\n",
            "Test score: [0.3091690242290497, 0.8723404407501221]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PART 2: MAKING PREDICTIONS**"
      ],
      "metadata": {
        "id": "ZguRmnIl5vKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "P = model.predict(X_test)\n",
        "print(P) # they are the outputs of the sigmoid, interpreted as probabilities p(y=1|x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frdGmbDa0JW1",
        "outputId": "b380235f-eedd-4260-cf5b-35ac03fcb9b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.4791809e-01]\n",
            " [8.1486726e-01]\n",
            " [4.1660291e-01]\n",
            " [4.6636501e-08]\n",
            " [9.3255007e-01]\n",
            " [9.6024334e-01]\n",
            " [9.9505270e-01]\n",
            " [9.3287790e-01]\n",
            " [9.7158045e-01]\n",
            " [6.4151061e-01]\n",
            " [5.3290045e-01]\n",
            " [8.7389815e-01]\n",
            " [9.1720366e-01]\n",
            " [2.9173493e-04]\n",
            " [6.6478646e-01]\n",
            " [5.6317854e-01]\n",
            " [5.8847290e-01]\n",
            " [9.9721718e-01]\n",
            " [9.6041536e-01]\n",
            " [9.6720862e-01]\n",
            " [8.5451806e-01]\n",
            " [9.8228824e-01]\n",
            " [4.5130071e-01]\n",
            " [9.3012518e-01]\n",
            " [9.9528956e-01]\n",
            " [9.3938643e-01]\n",
            " [1.4796343e-01]\n",
            " [8.7432110e-01]\n",
            " [6.2999654e-01]\n",
            " [6.2516886e-01]\n",
            " [8.9960027e-01]\n",
            " [9.2787351e-09]\n",
            " [7.3036516e-01]\n",
            " [8.4397244e-01]\n",
            " [9.4052231e-01]\n",
            " [8.7623638e-01]\n",
            " [4.0722426e-15]\n",
            " [5.1395506e-02]\n",
            " [3.4192157e-01]\n",
            " [9.1126829e-02]\n",
            " [7.8309786e-01]\n",
            " [6.8410969e-01]\n",
            " [9.9344063e-01]\n",
            " [9.6818298e-01]\n",
            " [2.5850162e-01]\n",
            " [1.2740493e-04]\n",
            " [9.5136511e-01]\n",
            " [2.7317885e-20]\n",
            " [9.0710485e-01]\n",
            " [2.3985565e-02]\n",
            " [1.0969801e-09]\n",
            " [9.8191762e-01]\n",
            " [1.1809281e-04]\n",
            " [9.9734944e-01]\n",
            " [9.4121790e-01]\n",
            " [1.5565498e-09]\n",
            " [1.4395773e-02]\n",
            " [9.7168577e-01]\n",
            " [9.9061584e-01]\n",
            " [3.4310758e-02]\n",
            " [9.9573284e-01]\n",
            " [1.7732859e-02]\n",
            " [3.3083946e-02]\n",
            " [1.6031569e-05]\n",
            " [9.5200455e-01]\n",
            " [9.2493415e-01]\n",
            " [5.6374228e-01]\n",
            " [7.3566538e-01]\n",
            " [2.9094555e-16]\n",
            " [9.6995258e-01]\n",
            " [2.5321242e-14]\n",
            " [5.5340022e-01]\n",
            " [9.6212655e-02]\n",
            " [9.2816520e-01]\n",
            " [7.5274843e-01]\n",
            " [3.1116974e-07]\n",
            " [7.2353917e-01]\n",
            " [9.7357309e-01]\n",
            " [9.8411721e-01]\n",
            " [9.9674779e-01]\n",
            " [9.5971471e-01]\n",
            " [9.2830491e-01]\n",
            " [8.9606905e-01]\n",
            " [2.0565118e-13]\n",
            " [9.8213309e-01]\n",
            " [4.8522949e-03]\n",
            " [9.6182042e-01]\n",
            " [9.9679840e-01]\n",
            " [3.6106372e-01]\n",
            " [8.9798105e-01]\n",
            " [9.9654841e-01]\n",
            " [9.6363246e-01]\n",
            " [9.7074264e-01]\n",
            " [9.8634100e-01]\n",
            " [1.9135285e-07]\n",
            " [9.9440104e-01]\n",
            " [9.4072068e-01]\n",
            " [7.5390947e-01]\n",
            " [1.3676569e-11]\n",
            " [1.9163203e-01]\n",
            " [9.6159983e-01]\n",
            " [9.7820163e-03]\n",
            " [2.7129084e-02]\n",
            " [3.8398206e-02]\n",
            " [2.0039082e-04]\n",
            " [1.1311017e-07]\n",
            " [8.8425195e-01]\n",
            " [9.9080700e-01]\n",
            " [4.0405969e-12]\n",
            " [9.0284896e-01]\n",
            " [9.0801677e-06]\n",
            " [9.7260678e-01]\n",
            " [9.5918608e-01]\n",
            " [2.2962028e-01]\n",
            " [3.1673771e-01]\n",
            " [9.6725655e-01]\n",
            " [9.7580230e-01]\n",
            " [4.3778601e-01]\n",
            " [9.4502783e-01]\n",
            " [2.8897226e-03]\n",
            " [9.1436028e-01]\n",
            " [3.8465059e-01]\n",
            " [2.5586862e-06]\n",
            " [6.2226565e-05]\n",
            " [8.8063562e-01]\n",
            " [5.9249642e-06]\n",
            " [4.8562753e-01]\n",
            " [9.9492979e-01]\n",
            " [9.8076087e-01]\n",
            " [9.5260811e-01]\n",
            " [7.3330812e-05]\n",
            " [8.5363299e-01]\n",
            " [8.0284810e-01]\n",
            " [8.1867474e-01]\n",
            " [9.7927607e-14]\n",
            " [1.0821819e-03]\n",
            " [9.3391967e-01]\n",
            " [9.1414380e-01]\n",
            " [9.3893600e-01]\n",
            " [9.6258801e-01]\n",
            " [6.4467931e-01]\n",
            " [3.6537909e-05]\n",
            " [9.6296340e-01]\n",
            " [7.2869821e-06]\n",
            " [9.9153674e-01]\n",
            " [9.7691494e-01]\n",
            " [9.4418621e-01]\n",
            " [9.1078722e-01]\n",
            " [9.6233737e-01]\n",
            " [9.8562443e-01]\n",
            " [1.0233122e-01]\n",
            " [2.3500712e-09]\n",
            " [1.5616417e-04]\n",
            " [9.6497703e-01]\n",
            " [9.6818256e-01]\n",
            " [4.6188980e-13]\n",
            " [6.8249935e-01]\n",
            " [1.6458586e-08]\n",
            " [8.1280208e-01]\n",
            " [5.1293582e-01]\n",
            " [2.4515120e-05]\n",
            " [9.3293846e-01]\n",
            " [6.2586576e-02]\n",
            " [9.8051244e-01]\n",
            " [7.6145518e-01]\n",
            " [8.9712131e-01]\n",
            " [8.4526384e-01]\n",
            " [5.3833187e-01]\n",
            " [9.5458472e-01]\n",
            " [9.9650037e-01]\n",
            " [9.0574408e-01]\n",
            " [3.1076880e-07]\n",
            " [3.2924458e-01]\n",
            " [9.9119401e-01]\n",
            " [9.8574138e-01]\n",
            " [1.9466877e-04]\n",
            " [1.3792818e-09]\n",
            " [2.4575255e-07]\n",
            " [9.6127975e-01]\n",
            " [6.4968508e-01]\n",
            " [8.1976712e-01]\n",
            " [2.6166437e-05]\n",
            " [9.8727739e-01]\n",
            " [4.5971891e-01]\n",
            " [8.9600289e-01]\n",
            " [2.8989702e-02]\n",
            " [6.2440014e-01]\n",
            " [9.9963856e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vjaRWEb1E-i",
        "outputId": "2c8339f0-0624-4cbb-a999-58cd30d3d1c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy, and compare it to the evaluate() output\n",
        "print(f'Manually calculated accuracy: {np.mean(P == y_test)}')\n",
        "print(f'Evaluate output: {model.evaluate(X_test, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2msX80ux1maG",
        "outputId": "b9abd7e3-542e-4e30-a10a-39be635b2947"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually calculated accuracy: 0.8723404255319149\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8723\n",
            "Evaluate output: [0.3091690242290497, 0.8723404407501221]\n"
          ]
        }
      ]
    }
  ]
}